---
layout: post
title: Sanitising HTML with C# and Tidy
date: '2008-10-26T14:19:00.000Z'
author: Rob
tags:
- Programming
- HTML
modified_time: '2013-10-17T21:53:49.272+01:00'
blogger_id: tag:blogger.com,1999:blog-7583560609041238092.post-3320737402757116637
blogger_orig_url: http://robertbeal.blogspot.com/2008/10/sanitising-html-with-c-and-tidy.html
---

<p>(*See article end for updates)</p> <p>A while back I was given the task of sanitising HTML entered in by users in our Discussions are at <a href="http://www.huddle.net" target="_blank">Huddle</a>. After searching around I initially couldn't find many easy to implement tools out there to help me.</p> <p>I firstly came across <a href="http://www.codinghorror.com/blog/">Jeff Atwood's</a> solution for cleaning HTML. A very fast solution, although not water tight. Regular expressions are great for string matching when you know what to expect, but in many cases the attacks are written so randomly it's possible for them to slip through.</p><a name='more'></a> <p>The best approach to Jeff's method would be to HtmlEncode the whole string, then anything "safe" that is matched in the encoded string, is decoded back. This would be a true whitelist solution (as opposed to blacklisting). In fact prior to that it would first be better to clean up the HTML.</p> <p>Hence, next I came across the <a href="http://www.codeplex.com/htmlagilitypack" target="_blank">HTML Agility Pack</a>, and <a href="http://sourceforge.net/projects/tidynet/" target="_blank">Tidy.Net</a> (a .Net port). Both of which are html parsers, and in Tidy's case, a cleaner too.</p> <p>I decided to go with the more mature product, <a href="http://tidy.sourceforge.net/" target="_blank">Tidy</a>. There were two choices, to use the original version of Tidy (using some sort of <a href="http://www.codeproject.com/KB/cs/ZetaHtmlTidy.aspx" target="_blank">COM wrapper</a>) or opt for Tidy.Net (a less mature .Net port). For speed, and ease I went for Tidy.Net.</p> <p>Before writing any application code I went to <a href="http://ha.ckers.org/xss.html" target="_blank">http://ha.ckers.org/xss.html</a>, and for each attack I wrote a unit test. My current solution can be found on Refactor My Code. It's by no means perfect, but at the moment is working well enough. I do plan to re-visit it though and finish up a few things. In fact once finished I'll post the zip of the code on here.</p> <p>Here's a quick walk-through of it:</p> <ol>    <li>The HTML string is passed to Tidy.Net and cleaned. Tidy.Net takes care of making sure the HTML is well formed, this makes pattern matching with a regular expression much more easier and accurate.</li>    <li>The output from Tidy.Net has to be cleaned slightly as it adds html, head, body etc... tags to the output (which we don't need).</li>    <li>Once cleaned I apply pattern matching. One thing I will be changing is to HtmlEncode the whole string, and then Decode any safe matches back. This would ensure proper whitelisting.</li>    <li>Using a static dictionary collection I can specify the allowed tags and attributes. There's potential to improve this, possibly using XML and loading it via IoC (as a singleton).</li></ol> <p>I'll try to update the code and get it published in the next week or two.</p> <p><strong>UPDATE - 19/01/2009</strong></p> <p>Here's the <a href="http://www.robertbeal.com/wp-content/uploads/2009/06/htmlutility.zip">latest code</a> as it stands. It still needs work, this update just addresses a few odds bugs in Tidy.Net I found (spaces being removed, line breaks being added etc...). I haven't looked at whitelisting yet, not had time (just got back from snowboarding in the alps), plus I've got loads of other stuff still on.</p> <p><strong>UPDATE - 06/06/2009</strong></p> <p>In the above <a href="http://www.robertbeal.com/wp-content/uploads/2009/06/htmlutility.zip">latest code link</a>, I've now included some of the unit tests. Around 15 I think. There are about another 6 but I need to clean them up.</p>